{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChromaGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzHbG/Z2z9/WWb+wOgLp6J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KunalVaidya99/Image-Colorization-Using-Deep-Learning/blob/main/ChromaGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA8bcFbU0-VF",
        "outputId": "c41fa961-c37a-4c67-b537-a49739e99138",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CswEHXhU1YDR",
        "outputId": "3177c9bf-0f77-4592-c067-0c26b25d9018",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/5wErqiQHCitTE68WhpVMh6UbS2PuPLfWezYydwDKREoms0b94esL8TY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaoB1Kbu1iXX",
        "outputId": "e27aed45-944d-4c57-9f95-8c6033495bb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.layers import (Conv2D,Conv2DTranspose,UpSampling2D,MaxPooling2D,Input\n",
        "                          ,Activation,Concatenate,BatchNormalization)\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import load_img\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.applications import VGG16\n",
        "from keras.preprocessing.image import load_img,img_to_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWGloSyGgyav"
      },
      "source": [
        "Extracting Features for all images using VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKF4y_Cc2pe0",
        "outputId": "ef80a5a5-99eb-4e5f-cde9-e156a1015496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def extract_features(directory):\n",
        "\n",
        "  model = VGG16(include_top=True,weights=\"imagenet\",classes=1000)\n",
        "  features = dict()\n",
        "  count = 0\n",
        "  for filename in os.listdir(directory):\n",
        "   \n",
        "    image = load_img(directory+filename,target_size=(224,224))\n",
        "    img_array = img_to_array(image)\n",
        "    img_array = img_array.reshape((1,224,224,3))\n",
        "    feature = model.predict(img_array)\n",
        "    features[filename] = feature\n",
        "    count = count + 1\n",
        "\n",
        "    if (count%1000==0):\n",
        "      print(\"Completed Feature Extraction Of \" + f\"{count}\") \n",
        "\n",
        "  return features\n",
        "\n",
        "directory = \"/content/gdrive/My Drive/val_256/\"\n",
        "features = extract_features(directory)       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Completed Feature Extraction Of 1000\n",
            "Completed Feature Extraction Of 2000\n",
            "Completed Feature Extraction Of 3000\n",
            "Completed Feature Extraction Of 4000\n",
            "Completed Feature Extraction Of 5000\n",
            "Completed Feature Extraction Of 6000\n",
            "Completed Feature Extraction Of 7000\n",
            "Completed Feature Extraction Of 8000\n",
            "Completed Feature Extraction Of 9000\n",
            "Completed Feature Extraction Of 10000\n",
            "Completed Feature Extraction Of 11000\n",
            "Completed Feature Extraction Of 12000\n",
            "Completed Feature Extraction Of 13000\n",
            "Completed Feature Extraction Of 14000\n",
            "Completed Feature Extraction Of 15000\n",
            "Completed Feature Extraction Of 16000\n",
            "Completed Feature Extraction Of 17000\n",
            "Completed Feature Extraction Of 18000\n",
            "Completed Feature Extraction Of 19000\n",
            "Completed Feature Extraction Of 20000\n",
            "Completed Feature Extraction Of 21000\n",
            "Completed Feature Extraction Of 22000\n",
            "Completed Feature Extraction Of 23000\n",
            "Completed Feature Extraction Of 24000\n",
            "Completed Feature Extraction Of 25000\n",
            "Completed Feature Extraction Of 26000\n",
            "Completed Feature Extraction Of 27000\n",
            "Completed Feature Extraction Of 28000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6GuKhL-5-aT",
        "outputId": "91d0ce19-303b-495d-dcb1-d0adfdfad2e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "import pickle\n",
        "f = open(\"/content/gdrive/My Drive/ImageColorization /chromaVGG16.pkl\",\"wb\")\n",
        "pickle.dump(features,f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnsupportedOperation",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e7546fe66255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/ImageColorization /chromaVGG16.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnsupportedOperation\u001b[0m: read"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoHf2gb8yFA_",
        "outputId": "2b006199-f026-4939-dcc2-7f1c75d8f929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "f_new = open(\"/content/gdrive/My Drive/ImageColorization /chromaVGG16.pkl\",\"rb\")\n",
        "features = pickle.load(f_new)\n",
        "f_new.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2699a90536f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/ImageColorization /chromaVGG16.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mf_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYtomIhCJfZf"
      },
      "source": [
        "class DataGenerator():\n",
        "\n",
        "  def __init__(self,features,directory,dim=(224,224),batch_size=32,n_channels=3):\n",
        "    \n",
        "    self.directory = directory\n",
        "    self.dim = dim\n",
        "    self.batch_size=batch_size\n",
        "    self.n_channels = n_channels\n",
        "    self.features = features\n",
        "    self.epoch_end()\n",
        "\n",
        "  def epoch_end(self,filenames):\n",
        "    np.random.shuffle(filenames)\n",
        "\n",
        "  def generate_batch(self,step_number,filenames):\n",
        "    \n",
        "\n",
        "    batch_filenames = filenames[step_number*self.batch_size:(step_number+1)*self.batch_size]\n",
        "\n",
        "    gray_image = np.empty((self.batch_size,*self.dim,self.n_channels))\n",
        "    color_image = np.empty((self.batch_size,*self.dim,self.n_channels))\n",
        "    VGG16_target = np.empty((self.batch_size,1000,1))\n",
        "    count = 0\n",
        "\n",
        "\n",
        "    for filename in batch_filenames:\n",
        "      image = Image.open(self.directory +\"/\" + filename,target_size=(224,224))\n",
        "      image = image.resize((224,224))\n",
        "\n",
        "\n",
        "      if (np.array(image).shape==(224,224,3)):\n",
        "        \n",
        "        gray_image[count] = (np.expand_dims(np.array(image.convert(\"L\")),axis=-1))/255\n",
        "        color_image[count] = np.array(image)/255\n",
        "        VGG16_target = self.features[filename]\n",
        "\n",
        "    return gray_image,color_image,VGG16_target    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACE0LabGvNW5"
      },
      "source": [
        "def patch_discriminator(img_shape):\n",
        "\n",
        "  input_img = Input(shape=img_shape)\n",
        "\n",
        "  X = Conv2D(filters=64,kernel_size=(4,4),strides=(2,2),padding='same')(input_img)\n",
        "  X = BatchNormalization(axis=-1)(X)\n",
        "  X = LeakyReLU(alpha=0.2)(X)\n",
        "\n",
        "  X = Conv2D(filters=128,kernel_size=(4,4),strides=(2,2),padding='same')(X)\n",
        "  X = BatchNormalization(axis=-1)(X)\n",
        "  X = LeakyReLU(alpha=0.2)(X)\n",
        "\n",
        "  X = Conv2D(filters=256,kernel_size=(4,4),strides=(2,2),padding='same')(X)\n",
        "  X = BatchNormalization(axis=-1)(X)\n",
        "  X = LeakyReLU(alpha=0.2)(X)\n",
        "\n",
        "  X = Conv2D(filters=512,kernel_size=(4,4),strides=(1,1),padding='same')(X)\n",
        "  X = BatchNormalization(axis=-1)(X)\n",
        "  X = LeakyReLU(alpha=0.2)(X)\n",
        "\n",
        "  X = Conv2D(filters=1,kernel_size=(4,4),strides=(1,1),padding='same')(X)\n",
        "  X = BatchNormalization(axis=-1)(X)\n",
        "  X = LeakyReLU(alpha=-1)(X)\n",
        "\n",
        "  model = Model(inputs=input_img,outputs=X)\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdKr1KpI8ALT",
        "outputId": "fd72a675-08bb-42bf-eff0-eb21c78ad2b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "patch_discriminator = patch_discriminator((224,224,3))\n",
        "patch_discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 112, 112, 64)      3136      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 56, 56, 128)       131200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 256)       524544    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2097664   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 28, 28, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 28, 28, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 28, 28, 1)         8193      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 28, 28, 1)         4         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 2,768,581\n",
            "Trainable params: 2,766,659\n",
            "Non-trainable params: 1,922\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgukDnq_8Uv0"
      },
      "source": [
        " model = VGG16(include_top=False,weights=\"imagenet\",classes=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVp9NhQx8IZP"
      },
      "source": [
        "def generator(img_shape):\n",
        "\n",
        "  input_img = Input(shape=img_shape)\n",
        "  X = input_img\n",
        "\n",
        "  for layer in model.layers[:-6]:\n",
        "    X = layer(X)\n",
        "  \n",
        "  VGG16_output = X \n",
        "  X = Conv2D(filters=512,kernel_size=(3,3),strides=(2,2),padding=\"same\")(X)\n",
        "  X = BatchNormalization(axis=-1)(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\"same\")(X)\n",
        "  X = BatchNormalization(axis=-1)(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(filters=512,kernel_size=(3,3),strides=(2,2),padding=\"same\")(X)\n",
        "  X = BatchNormalization(axis=-1)(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\"same\")(X)\n",
        "  X = BatchNormalization(axis=-1)(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  color_distribution = Flatten()(X)\n",
        "  color_distribution = Dense(units=4096)\n",
        "  color_distribution = Dense(units=4096)\n",
        "  color_distribution = Dense(units=1000,activation='softmax')\n",
        "\n",
        "  fusion = Flatten()(X)\n",
        "  fusion = Dense(units=1024)\n",
        "  fusion = Dense(units=512)\n",
        "  fusion = Dense(units=256)\n",
        "  fusion = RepeatVector(28*28)(fusion)\n",
        "\n",
        "  encoder_output = Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding=\"same\")(VGG16_output)\n",
        "  encoder_output = BatchNormalization(axis=-1)(encoder_output)\n",
        "  encoder_output = Activation('relu')(X)\n",
        "  encoder_output = Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"same\")(VGG16_output)\n",
        "  encoder_output = BatchNormalization(axis=-1)(encoder_output)\n",
        "  encoder_output = Activation('relu')(X)\n",
        "\n",
        "  encoder_output = Concatenate(axis=-1)([encoder_output,fusion])\n",
        "\n",
        "  decoder = Conv2D(filters=256,kernel_size=(1,1),strides=(1,1),activation='relu',padding='same')(encoder_output)\n",
        "  decoder = Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(decoder)\n",
        "  decoder = UpSampling2D((2,2))(decoder)\n",
        "\n",
        "  decoder = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(decoder)\n",
        "  decoder = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(decoder)\n",
        "  decoder = UpSampling2D((2,2))(decoder)\n",
        "\n",
        "  decoder = Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(decoder)\n",
        "  decoder = Conv2D(filters=3,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(decoder)\n",
        "  decoder = UpSampling2D((2,2))(decoder)\n",
        "\n",
        "\n",
        "  model = Model(inputs=input_img,outputs=[decoder,color_distribution])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}